\documentclass[11pt]{article}
\usepackage{amsmath}
\usepackage{graphicx}
\graphicspath{{img/}}

\begin{document}

\title{{\bf 11-755: MLSP}\\
       HW \#3: Clustering and EM}

\author{Nikolas Wolfe}

\date{December 15, 2015}
\maketitle


\section*{Problem 1: K-Means \& Spectral Clustering}
You are given a number of toy datasets. The visulized groud truth clustering configuration of these data: Aggregation (K=7), Bridge (K=2), Compound (K=6), Flame (K=2), Jain (K=2), Spiral (K=3) and TwoDiamond (K=2) are shown as follows:
\begin{center}
\includegraphics[scale=0.5]{aggregation}
\includegraphics[scale=0.5]{bridge}
\includegraphics[scale=0.5]{compound}
\includegraphics[scale=0.5]{flame}
\includegraphics[scale=0.5]{jain}
\includegraphics[scale=0.5]{spiral}
\includegraphics[scale=0.5]{twoDiamonds}
\end{center}
{\bf Answer:} 
I implemented this code in Java, using the Efficient Java Matrix Library (EJML) package to do matrix multiplication and Eigen/Singular Value decomposition. In general, spectral clustering works a lot better than K-means and is able to determine a lot of structure (such as the spiral pattern) that k-means is unable to find. 

In terms of evaluation, I ran the clustering algorithms and generated the confusion matrix between the most common label that emerges in each cluster and their actual labels. A diagonal matrix in this case is of course perfect performance. The accuracy can be determined from looking at the counts of labelled points for each class. 
%\pagebreak
\section*{Problem 2: Expectation Maximization}

\end{document}